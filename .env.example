# LLM Provider Configuration
# Choose provider: "codex" or "claude"
LLM_PROVIDER=codex
LLM_MODEL=gpt-5-codex

# OpenAI Codex Configuration (if using codex)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_ORG_ID=your_org_id_here

# Anthropic Claude Configuration (if using claude)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Optional: Override default LLM parameters
# LLM_TEMPERATURE=0.1
# LLM_MAX_TOKENS=3000
# LLM_TIMEOUT_MS=120000

# Test Execution Configuration
E2E_BASE_URL=http://localhost:4200

# Test credentials (replace with your test accounts)
E2E_USER_EMAIL=qa.user@example.com
E2E_USER_PASSWORD=SuperSecure123!
INVALID_PASSWORD=WrongPassword!
UNKNOWN_EMAIL=unknown.user@example.com

# CI Configuration (optional)
# CI=true

# Stagehand authoring controls
# Set AUTHORING_MODE=true only during local authoring when LLM calls are allowed.
AUTHORING_MODE=false
STAGEHAND_CACHE_DIR=.stagehand-cache

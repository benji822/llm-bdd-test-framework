import os from 'node:os';
import path from 'node:path';

import { createLLMProvider, LLMProvider, withLLMRetry } from './llm';
import type { LLMCompletionMetadata, LLMCompletionOptions } from './llm';
import { ensureDir, readTextFile, writeTextFile } from './utils/file-operations';
import { renderPrompt } from './utils/prompt-loader';
import { sanitizeFeatureOutput } from './utils/sanitizers';
import { NormalizedYamlSchema, type NormalizedYaml, type NormalizedStep } from './types/yaml-spec';
import { parseYaml, stringifyYaml } from './utils/yaml-parser';
import { validateFeatureCoverage } from './validate-coverage';
import { createPromptCacheKey, getCachedCompletion, setCachedCompletion } from './utils/llm-cache';
import { appendLLMAuditEntry } from './audit-log';
import { runConcurrent } from './utils/concurrent';

interface GenerateFeatureParams {
  yamlPath: string;
  outputDir?: string;
  provider?: LLMProvider;
  vocabularyPath?: string;
  llmOptions?: Partial<Pick<LLMCompletionOptions, 'model' | 'temperature' | 'maxTokens' | 'timeoutMs'>>;
}

interface GenerateFeatureResult {
  outputPaths: string[];
  metadata: LLMCompletionMetadata;
}

interface GenerateFeatureBatchParams extends Omit<GenerateFeatureParams, 'yamlPath'> {
  yamlPaths: string[];
  concurrency?: number;
}

const PROMPT_PATH = path.resolve('tests/prompts/yaml-to-features.md');
const DEFAULT_OUTPUT_DIR = path.resolve('tests/features');

export async function generateFeatureFiles(params: GenerateFeatureParams): Promise<GenerateFeatureResult> {
  const { yamlPath } = params;
  const yamlContent = await readTextFile(path.resolve(yamlPath));
  const normalized = NormalizedYamlSchema.parse(parseYaml(yamlContent));

  const vocabularyPath = params.vocabularyPath ?? path.resolve('tests/artifacts/step-vocabulary.json');
  const vocabularyJson = await readTextFile(vocabularyPath);

  const prompt = await renderPrompt(PROMPT_PATH, {
    YAML_SPEC: stringifyYaml(normalized),
    STEP_VOCABULARY_JSON: vocabularyJson,
    SELECTOR_REGISTRY_SNIPPET: '',
  });

  const provider = params.provider ?? createLLMProvider();
  const llmOptions = buildLlmOptions(provider.name, params.llmOptions);
  const cacheKey = createPromptCacheKey(prompt, provider.name, llmOptions.model, {
    stage: 'generate-features',
    temperature: llmOptions.temperature,
  });

  const cached = await getCachedCompletion(cacheKey);
  const completion =
    cached ??
    (await withLLMRetry(
      () => provider.generateCompletion(prompt, llmOptions),
      { provider: provider.name },
    ));

  if (!cached) {
    await setCachedCompletion(cacheKey, completion);
  }

  let sanitized = sanitizeFeatureOutput(completion.completion);

  if (!/^Feature:/m.test(sanitized) || !/^(?:\s*@\w+\s*)*\s*(Scenario|Scenario Outline):/m.test(sanitized)) {
    sanitized = buildFeatureFromNormalized(normalized);
  }

  sanitized = maskSensitivePlaceholders(sanitized);
  const featureName = createSlug(normalized.feature);
  const outputDir = params.outputDir ?? DEFAULT_OUTPUT_DIR;
  const featurePath = path.join(outputDir, `${featureName}.feature`);

  await ensureDir(path.dirname(featurePath));
  const featureWithMetadata = appendMetadataComment(sanitized, completion.metadata);
  await writeTextFile(featurePath, `${featureWithMetadata}\n`);

  await appendLLMAuditEntry({
    stage: 'generate-features',
    provider: completion.metadata.provider,
    model: completion.metadata.model,
    tokensUsed: completion.metadata.tokensUsed,
    responseTimeMs: completion.metadata.responseTime,
    prompt,
    response: completion.completion,
    cached: Boolean(cached),
    promptHash: cacheKey,
    metadata: { yamlPath },
  });

  await runGherkinLint(featurePath);

  await validateFeatureCoverage({
    featurePaths: [featurePath],
    vocabularyPath,
  });

  return {
    outputPaths: [featurePath],
    metadata: completion.metadata,
  };
}

export async function generateFeatureFilesBatch(params: GenerateFeatureBatchParams): Promise<GenerateFeatureResult[]> {
  if (params.yamlPaths.length === 0) {
    return [];
  }

  const provider = params.provider ?? createLLMProvider();
  const concurrency = Math.max(
    1,
    Math.min(params.concurrency ?? Math.max(1, os.cpus().length - 1), params.yamlPaths.length),
  );

  const tasks = params.yamlPaths.map(
    (yamlPath) => () =>
      generateFeatureFiles({
        ...params,
        provider,
        yamlPath,
      }),
  );

  return runConcurrent(tasks, concurrency);
}

function appendMetadataComment(content: string, metadata: LLMCompletionMetadata): string {
  const lines = content.trimEnd().split(/\r?\n/);
  const comment = `# Generated by ${metadata.provider} ${metadata.model}`;
  if (!lines[lines.length - 1].startsWith('#')) {
    lines.push('');
  }
  lines.push(comment);
  return lines.join('\n');
}

function buildFeatureFromNormalized(normalized: NormalizedYaml): string {
  const lines: string[] = [];
  lines.push(`Feature: ${normalized.feature}`);
  if (normalized.description) {
    lines.push(`  ${normalized.description}`);
  }

  if (normalized.background?.steps?.length) {
    lines.push('');
    lines.push('  Background:');
    for (const step of normalized.background.steps) {
      lines.push(`    ${formatStepKeyword(step.type)} ${step.text}`);
    }
  }

  for (const scenario of normalized.scenarios) {
    lines.push('');
    if (scenario.tags?.length) {
      lines.push(`  ${scenario.tags.map((tag) => `@${tag}`).join(' ')}`);
    }
    lines.push(`  Scenario: ${scenario.name}`);
    for (const step of scenario.steps) {
      lines.push(`    ${formatStepKeyword(step.type)} ${step.text}`);
    }
  }

  return lines.join('\n');
}

function formatStepKeyword(type: NormalizedStep['type']): string {
  switch (type) {
    case 'given':
      return 'Given';
    case 'when':
      return 'When';
    case 'then':
      return 'Then';
    case 'and':
      return 'And';
    case 'but':
      return 'But';
    default:
      return 'And';
  }
}

function maskSensitivePlaceholders(featureContent: string): string {
  return featureContent.replace(/"([^"]+)"/g, (_match, value: string) => `"${mapPlaceholder(value)}"`);
}

function mapPlaceholder(value: string): string {
  if (value.includes('@')) {
    return '<E2E_USER_EMAIL>';
  }
  if (/password|secret|token/i.test(value)) {
    return '<E2E_USER_PASSWORD>';
  }
  return value;
}

async function runGherkinLint(featurePath: string): Promise<void> {
  const linter = await import('gherkin-lint/dist/linter');
  const configPath = path.resolve('tests/config/gherkinlint.json');
  const configuration = await loadLintConfiguration(configPath);
  const results = await linter.lint([featurePath], configuration, []);
  const errors = (results ?? [])
    .flatMap((result: { errors?: Array<{ message: string; rule: string; severity?: string }> }) => result.errors ?? [])
    .filter((error: { severity?: string }) => (error.severity ?? 'error').toLowerCase() === 'error');

  if (errors.length > 0) {
    const details = errors.map((error: { message: string; rule: string }) => `${error.rule}: ${error.message}`);
    throw new Error(`Gherkin lint failed:\n${details.join('\n')}`);
  }
}

async function loadLintConfiguration(configPath: string): Promise<Record<string, unknown>> {
  try {
    const raw = await readTextFile(configPath);
    return JSON.parse(raw);
  } catch (error) {
    if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
      return { default: true };
    }
    throw error;
  }
}

function buildLlmOptions(
  providerName: string,
  overrides?: GenerateFeatureParams['llmOptions'],
): LLMCompletionOptions {
  const defaultModel =
    overrides?.model ?? process.env.LLM_MODEL ?? (providerName === 'claude' ? 'claude-3-opus' : 'codex-typescript');

  return {
    model: defaultModel,
    temperature: overrides?.temperature ?? readNumberEnv('LLM_TEMPERATURE', 0.2),
    maxTokens: overrides?.maxTokens ?? readNumberEnv('LLM_MAX_TOKENS', 4000),
    timeoutMs: overrides?.timeoutMs ?? readNumberEnv('LLM_TIMEOUT_MS', 180000),
  };
}

function readNumberEnv(key: string, fallback: number): number {
  const raw = process.env[key];
  if (!raw) {
    return fallback;
  }
  const parsed = Number(raw);
  return Number.isFinite(parsed) ? parsed : fallback;
}
function createSlug(value: string): string {
  return value
    .toLowerCase()
    .trim()
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '');
}

export type { GenerateFeatureParams, GenerateFeatureResult };
